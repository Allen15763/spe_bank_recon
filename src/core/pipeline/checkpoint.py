"""
Pipeline Checkpoint ç³»çµ±
æä¾› pipeline åŸ·è¡Œç‹€æ…‹çš„å„²å­˜å’Œæ¢å¾©åŠŸèƒ½ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰

åŠŸèƒ½:
1. å„²å­˜ pipeline åŸ·è¡Œçš„ä¸­é–“ç‹€æ…‹
2. å¾æŒ‡å®šæ­¥é©Ÿæ¢å¾©åŸ·è¡Œ
3. å¿«é€Ÿæ¸¬è©¦å¾ŒçºŒæ­¥é©Ÿ

ä½¿ç”¨æ–¹å¼:
    # é¦–æ¬¡åŸ·è¡Œ - è‡ªå‹•å„²å­˜ checkpoint
    result = execute_with_checkpoint(pipeline, context, save_checkpoints=True)
    
    # å¾ç‰¹å®šæ­¥é©Ÿæ¢å¾©
    result = resume_from_checkpoint(
        checkpoint_name="task_202501_after_Clean_Data",
        start_from_step="Transform_Data",
        pipeline=pipeline
    )
"""

import json
import shutil
from pathlib import Path
from typing import Dict, Any, Optional, List, Callable
from datetime import datetime

import pandas as pd

from .context import ProcessingContext
from .pipeline import Pipeline
from .base import StepResult, StepStatus
from src.utils import get_logger, config_manager


class CheckpointManager:
    """Pipeline Checkpoint ç®¡ç†å™¨"""
    
    def __init__(self, checkpoint_dir: str = None):
        """
        åˆå§‹åŒ– Checkpoint ç®¡ç†å™¨
        
        Args:
            checkpoint_dir: checkpoint å„²å­˜ç›®éŒ„ï¼Œé è¨­å¾é…ç½®è®€å–
        """
        if checkpoint_dir is None:
            checkpoint_dir = config_manager.get('paths', 'temp_path', './checkpoints')
        
        self.checkpoint_dir = Path(checkpoint_dir) / 'checkpoints'
        self.checkpoint_dir.mkdir(parents=True, exist_ok=True)
        self.logger = get_logger("checkpoint")
    
    def save_checkpoint(
        self,
        context: ProcessingContext,
        step_name: str,
        metadata: Optional[Dict] = None
    ) -> str:
        """
        å„²å­˜ checkpoint
        
        Args:
            context: è™•ç†ä¸Šä¸‹æ–‡
            step_name: æ­¥é©Ÿåç¨±
            metadata: é¡å¤–çš„å…ƒæ•¸æ“š
            
        Returns:
            str: checkpoint åç¨±
        """
        # ç”Ÿæˆ checkpoint åç¨±
        task_name = context.metadata.task_name or "unknown"
        task_type = context.metadata.task_type or "unknown"
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        checkpoint_name = f"{task_name}_{task_type}_after_{step_name}"
        checkpoint_path = self.checkpoint_dir / checkpoint_name
        checkpoint_path.mkdir(parents=True, exist_ok=True)
        
        # å„²å­˜ä¸»æ•¸æ“š
        if context.data is not None and not context.data.empty:
            data_path = checkpoint_path / "data.parquet"
            try:
                context.data.to_parquet(data_path, index=False)
            except Exception as e:
                # å¦‚æœ parquet å¤±æ•—ï¼Œå˜—è©¦ pickle
                self.logger.warning(f"Parquet å„²å­˜å¤±æ•—ï¼Œå˜—è©¦ pickle: {e}")
                data_path = checkpoint_path / "data.pkl"
                context.data.to_pickle(data_path)
        
        # å„²å­˜è¼”åŠ©æ•¸æ“š
        aux_data_dir = checkpoint_path / "auxiliary_data"
        aux_data_dir.mkdir(exist_ok=True)
        
        for aux_name in context.list_auxiliary_data():
            aux_data = context.get_auxiliary_data(aux_name)
            if aux_data is not None and not aux_data.empty:
                try:
                    aux_path = aux_data_dir / f"{aux_name}.parquet"
                    aux_data.to_parquet(aux_path, index=False)
                except Exception as e:
                    self.logger.warning(f"è¼”åŠ©æ•¸æ“š {aux_name} parquet å„²å­˜å¤±æ•—: {e}")
                    try:
                        aux_path = aux_data_dir / f"{aux_name}.pkl"
                        aux_data.to_pickle(aux_path)
                    except Exception as e2:
                        self.logger.error(f"è¼”åŠ©æ•¸æ“š {aux_name} å„²å­˜å¤±æ•—: {e2}")
        
        # å„²å­˜è®Šæ•¸å’Œå…ƒæ•¸æ“šï¼ˆåºåˆ—åŒ–å®‰å…¨è™•ç†ï¼‰
        safe_variables = {}
        for k, v in context._variables.items():
            try:
                json.dumps(v)  # æ¸¬è©¦æ˜¯å¦å¯åºåˆ—åŒ–
                safe_variables[k] = v
            except (TypeError, ValueError):
                safe_variables[k] = str(v)  # è½‰ç‚ºå­—ä¸²
        
        checkpoint_info = {
            'step_name': step_name,
            'task_name': context.metadata.task_name,
            'task_type': context.metadata.task_type,
            'variables': safe_variables,
            'warnings': context.warnings,
            'errors': context.errors,
            'timestamp': timestamp,
            'auxiliary_data_list': context.list_auxiliary_data(),
            'data_shape': list(context.data.shape) if context.data is not None else [0, 0],
            'metadata': metadata or {}
        }
        
        with open(checkpoint_path / "checkpoint_info.json", 'w', encoding='utf-8') as f:
            json.dump(checkpoint_info, f, indent=2, ensure_ascii=False, default=str)
        
        self.logger.info(f"âœ… Checkpoint å·²å„²å­˜: {checkpoint_name}")
        return checkpoint_name
    
    def load_checkpoint(self, checkpoint_name: str) -> ProcessingContext:
        """
        è¼‰å…¥ checkpoint
        
        Args:
            checkpoint_name: checkpoint åç¨±
            
        Returns:
            ProcessingContext: æ¢å¾©çš„ä¸Šä¸‹æ–‡
        """
        checkpoint_path = self.checkpoint_dir / checkpoint_name
        
        if not checkpoint_path.exists():
            raise FileNotFoundError(f"Checkpoint ä¸å­˜åœ¨: {checkpoint_name}")
        
        # è¼‰å…¥å…ƒæ•¸æ“š
        with open(checkpoint_path / "checkpoint_info.json", 'r', encoding='utf-8') as f:
            info = json.load(f)
        
        # è¼‰å…¥ä¸»æ•¸æ“š
        data_parquet = checkpoint_path / "data.parquet"
        data_pkl = checkpoint_path / "data.pkl"
        
        if data_parquet.exists():
            data = pd.read_parquet(data_parquet)
        elif data_pkl.exists():
            data = pd.read_pickle(data_pkl)
        else:
            data = pd.DataFrame()
        
        # å‰µå»ºä¸Šä¸‹æ–‡
        context = ProcessingContext(
            data=data,
            task_name=info['task_name'],
            task_type=info['task_type']
        )
        
        # æ¢å¾©è®Šæ•¸
        for key, value in info['variables'].items():
            context.set_variable(key, value)
        
        # æ¢å¾©è­¦å‘Šå’ŒéŒ¯èª¤
        context.warnings = info.get('warnings', [])
        context.errors = info.get('errors', [])
        
        # æ¢å¾©è¼”åŠ©æ•¸æ“š
        aux_data_dir = checkpoint_path / "auxiliary_data"
        if aux_data_dir.exists():
            for aux_file in aux_data_dir.glob("*.parquet"):
                aux_name = aux_file.stem
                aux_data = pd.read_parquet(aux_file)
                context.add_auxiliary_data(aux_name, aux_data)
            
            for aux_file in aux_data_dir.glob("*.pkl"):
                aux_name = aux_file.stem
                if not context.has_auxiliary_data(aux_name):  # é¿å…é‡è¤‡
                    aux_data = pd.read_pickle(aux_file)
                    context.add_auxiliary_data(aux_name, aux_data)
        
        self.logger.info(f"âœ… Checkpoint å·²è¼‰å…¥: {checkpoint_name}")
        self.logger.info(f"   - ä¸»æ•¸æ“š: {len(context.data)} è¡Œ")
        self.logger.info(f"   - è¼”åŠ©æ•¸æ“š: {len(context.list_auxiliary_data())} å€‹")
        self.logger.info(f"   - è®Šæ•¸: {len(context._variables)} å€‹")
        
        return context
    
    def list_checkpoints(self, filter_task: str = None) -> List[Dict]:
        """
        åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„ checkpoint
        
        Args:
            filter_task: éæ¿¾ç‰¹å®šä»»å‹™åç¨±
            
        Returns:
            List[Dict]: checkpoint è³‡è¨Šåˆ—è¡¨
        """
        checkpoints = []
        
        for checkpoint_path in self.checkpoint_dir.iterdir():
            if checkpoint_path.is_dir():
                info_file = checkpoint_path / "checkpoint_info.json"
                if info_file.exists():
                    try:
                        with open(info_file, 'r', encoding='utf-8') as f:
                            info = json.load(f)
                        
                        # éæ¿¾ä»»å‹™
                        if filter_task and info.get('task_name') != filter_task:
                            continue
                        
                        checkpoints.append({
                            'name': checkpoint_path.name,
                            'step': info['step_name'],
                            'task_name': info.get('task_name', 'unknown'),
                            'task_type': info.get('task_type', 'unknown'),
                            'timestamp': info['timestamp'],
                            'data_shape': info.get('data_shape', [0, 0])
                        })
                    except Exception as e:
                        self.logger.warning(f"è®€å– checkpoint è³‡è¨Šå¤±æ•—: {checkpoint_path.name}, {e}")
        
        return sorted(checkpoints, key=lambda x: x['timestamp'], reverse=True)
    
    def delete_checkpoint(self, checkpoint_name: str) -> bool:
        """
        åˆªé™¤æŒ‡å®šçš„ checkpoint
        
        Args:
            checkpoint_name: checkpoint åç¨±
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸåˆªé™¤
        """
        checkpoint_path = self.checkpoint_dir / checkpoint_name
        if checkpoint_path.exists():
            shutil.rmtree(checkpoint_path)
            self.logger.info(f"âœ… Checkpoint å·²åˆªé™¤: {checkpoint_name}")
            return True
        return False
    
    def cleanup_old_checkpoints(self, keep_last: int = 5, task_name: str = None):
        """
        æ¸…ç†èˆŠçš„ checkpointï¼Œä¿ç•™æœ€è¿‘çš„ N å€‹
        
        Args:
            keep_last: ä¿ç•™æœ€è¿‘çš„æ•¸é‡
            task_name: æŒ‡å®šä»»å‹™åç¨±ï¼ŒNone è¡¨ç¤ºæ‰€æœ‰
        """
        checkpoints = self.list_checkpoints(filter_task=task_name)
        
        if len(checkpoints) > keep_last:
            to_delete = checkpoints[keep_last:]
            for cp in to_delete:
                self.delete_checkpoint(cp['name'])
            
            self.logger.info(f"æ¸…ç†äº† {len(to_delete)} å€‹èˆŠ checkpoint")


class PipelineWithCheckpoint:
    """
    å¸¶ Checkpoint åŠŸèƒ½çš„ Pipeline åŸ·è¡Œå™¨
    """
    
    def __init__(self, pipeline: Pipeline, checkpoint_manager: CheckpointManager = None):
        """
        åˆå§‹åŒ–
        
        Args:
            pipeline: Pipeline å¯¦ä¾‹
            checkpoint_manager: Checkpoint ç®¡ç†å™¨ï¼ŒNone å‰‡è‡ªå‹•å‰µå»º
        """
        self.pipeline = pipeline
        self.checkpoint_manager = checkpoint_manager or CheckpointManager()
        self.logger = get_logger("pipeline.checkpoint")
    
    def execute_with_checkpoint(
        self,
        context: ProcessingContext,
        save_after_each_step: bool = True,
        start_from_step: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        åŸ·è¡Œ Pipeline ä¸¦è‡ªå‹•å„²å­˜ checkpoint
        
        Args:
            context: è™•ç†ä¸Šä¸‹æ–‡
            save_after_each_step: æ˜¯å¦åœ¨æ¯å€‹æ­¥é©Ÿå¾Œå„²å­˜ checkpoint
            start_from_step: å¾å“ªå€‹æ­¥é©Ÿé–‹å§‹åŸ·è¡Œ (None = å¾é ­é–‹å§‹)
            
        Returns:
            Dict: åŸ·è¡Œçµæœ
        """
        start_time = datetime.now()
        
        # æ‰¾åˆ°èµ·å§‹æ­¥é©Ÿçš„ç´¢å¼•
        start_index = 0
        if start_from_step:
            for i, step in enumerate(self.pipeline.steps):
                if step.name == start_from_step:
                    start_index = i
                    self.logger.info(f"ğŸ”„ å¾æ­¥é©Ÿ '{start_from_step}' é–‹å§‹åŸ·è¡Œ (è·³éå‰ {i} å€‹æ­¥é©Ÿ)")
                    break
            else:
                raise ValueError(f"æ‰¾ä¸åˆ°æ­¥é©Ÿ: {start_from_step}")
        
        # åŸ·è¡Œæ­¥é©Ÿ
        results = []
        for i, step in enumerate(self.pipeline.steps[start_index:], start=start_index):
            self.logger.info(f"\n{'='*60}")
            self.logger.info(f"åŸ·è¡Œæ­¥é©Ÿ {i+1}/{len(self.pipeline.steps)}: {step.name}")
            self.logger.info(f"{'='*60}")
            
            # åŸ·è¡Œæ­¥é©Ÿ
            result = step(context)
            results.append(result)
            
            # è¨˜éŒ„åˆ°ä¸Šä¸‹æ–‡æ­·å²
            context.add_history(step.name, result.status.value)
            
            # å„²å­˜ checkpoint
            if save_after_each_step and result.is_success:
                self.checkpoint_manager.save_checkpoint(
                    context=context,
                    step_name=step.name,
                    metadata={
                        'step_index': i,
                        'step_status': result.status.value,
                        'step_message': result.message
                    }
                )
            
            # å¦‚æœå¤±æ•—ä¸”è¨­å®šç‚ºé‡éŒ¯å³åœ
            if not result.is_success and self.pipeline.config.stop_on_error:
                self.logger.error(f"âŒ æ­¥é©Ÿå¤±æ•—ï¼Œåœæ­¢åŸ·è¡Œ: {result.message}")
                break
        
        # å½™ç¸½çµæœ
        end_time = datetime.now()
        successful = sum(1 for r in results if r.is_success)
        failed = sum(1 for r in results if r.is_failed)
        skipped = sum(1 for r in results if r.status == StepStatus.SKIPPED)
        
        return {
            'success': failed == 0,
            'pipeline': self.pipeline.config.name,
            'start_time': start_time,
            'end_time': end_time,
            'duration': (end_time - start_time).total_seconds(),
            'total_steps': len(self.pipeline.steps),
            'executed_steps': len(results),
            'successful_steps': successful,
            'failed_steps': failed,
            'skipped_steps': skipped,
            'results': [r.to_dict() for r in results],
            'context': context
        }


# =============================================================================
# ä¾¿æ·å‡½æ•¸
# =============================================================================

def execute_with_checkpoint(
    pipeline: Pipeline,
    context: ProcessingContext,
    checkpoint_dir: str = None,
    save_checkpoints: bool = True
) -> Dict[str, Any]:
    """
    åŸ·è¡Œ pipeline ä¸¦è‡ªå‹•å„²å­˜ checkpoint
    
    Args:
        pipeline: Pipeline å¯¦ä¾‹
        context: è™•ç†ä¸Šä¸‹æ–‡
        checkpoint_dir: checkpoint å„²å­˜ç›®éŒ„
        save_checkpoints: æ˜¯å¦å„²å­˜ checkpoint
        
    Returns:
        Dict: åŸ·è¡Œçµæœ
    """
    checkpoint_manager = CheckpointManager(checkpoint_dir)
    executor = PipelineWithCheckpoint(pipeline, checkpoint_manager)
    
    return executor.execute_with_checkpoint(
        context=context,
        save_after_each_step=save_checkpoints
    )


def resume_from_checkpoint(
    checkpoint_name: str,
    start_from_step: str,
    pipeline: Pipeline,
    checkpoint_dir: str = None,
    save_checkpoints: bool = True
) -> Dict[str, Any]:
    """
    å¾ checkpoint æ¢å¾©ä¸¦å¾æŒ‡å®šæ­¥é©Ÿé–‹å§‹åŸ·è¡Œ
    
    Args:
        checkpoint_name: checkpoint åç¨±
        start_from_step: å¾å“ªå€‹æ­¥é©Ÿé–‹å§‹
        pipeline: Pipeline å¯¦ä¾‹
        checkpoint_dir: checkpoint ç›®éŒ„
        save_checkpoints: æ˜¯å¦å„²å­˜æ–°çš„ checkpoint
        
    Returns:
        Dict: åŸ·è¡Œçµæœ
    """
    checkpoint_manager = CheckpointManager(checkpoint_dir)
    context = checkpoint_manager.load_checkpoint(checkpoint_name)
    
    executor = PipelineWithCheckpoint(pipeline, checkpoint_manager)
    
    return executor.execute_with_checkpoint(
        context=context,
        save_after_each_step=save_checkpoints,
        start_from_step=start_from_step
    )


def list_available_checkpoints(
    checkpoint_dir: str = None,
    task_name: str = None
) -> List[Dict]:
    """
    åˆ—å‡ºå¯ç”¨çš„ checkpoint
    
    Args:
        checkpoint_dir: checkpoint ç›®éŒ„
        task_name: éæ¿¾ç‰¹å®šä»»å‹™
        
    Returns:
        List[Dict]: checkpoint è³‡è¨Šåˆ—è¡¨
    """
    checkpoint_manager = CheckpointManager(checkpoint_dir)
    return checkpoint_manager.list_checkpoints(filter_task=task_name)


def quick_test_step(
    checkpoint_name: str,
    step_to_test: str,
    pipeline: Pipeline,
    checkpoint_dir: str = None
) -> Dict[str, Any]:
    """
    å¿«é€Ÿæ¸¬è©¦å–®ä¸€æ­¥é©Ÿ (å¾ä¸Šä¸€å€‹ checkpoint æ¢å¾©)
    
    Args:
        checkpoint_name: checkpoint åç¨±
        step_to_test: è¦æ¸¬è©¦çš„æ­¥é©Ÿåç¨±
        pipeline: Pipeline å¯¦ä¾‹
        checkpoint_dir: checkpoint ç›®éŒ„
        
    Returns:
        Dict: åŸ·è¡Œçµæœ
    """
    return resume_from_checkpoint(
        checkpoint_name=checkpoint_name,
        start_from_step=step_to_test,
        pipeline=pipeline,
        checkpoint_dir=checkpoint_dir,
        save_checkpoints=False  # æ¸¬è©¦æ™‚ä¸å„²å­˜
    )
