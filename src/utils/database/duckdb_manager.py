import duckdb
import pandas as pd
from typing import Optional, Dict, Any
from datetime import datetime
import time
import os

from src.utils.logging import get_logger


class DuckDBManager:
    """
    DuckDB è³‡æ–™åº«ç®¡ç†å™¨

    ä½¿ç”¨é …ç›®çµ±ä¸€çš„æ—¥èªŒç³»çµ±é€²è¡Œæ—¥èªŒè¨˜éŒ„
    """

    def __init__(
        self,
        db_path: str = ":memory:"
    ):
        """
        åˆå§‹åŒ– DuckDB ç®¡ç†å™¨

        Args:
            db_path: è³‡æ–™åº«è·¯å¾‘ï¼Œé»˜èªç‚ºå…§å­˜æ¨¡å¼ ":memory:"
        """
        os.environ['TZ'] = 'Asia/Taipei'
        if hasattr(time, 'tzset'):
            os.environ['TZ'] = 'America/New_York'  # Example timezone
            time.tzset()
        else:
            print("time.tzset() is not available on this platform. Timezone changes may not take effect.")

        self.db_path = db_path
        self.conn = None

        # ä½¿ç”¨é …ç›®çµ±ä¸€çš„æ—¥èªŒç³»çµ±
        self.logger = get_logger('database.duckdb')

        self._connect()

    def _connect(self):
        """å»ºç«‹è³‡æ–™åº«é€£æ¥"""
        try:
            self.conn = duckdb.connect(self.db_path)
            self.logger.info(f"æˆåŠŸé€£æ¥åˆ° DuckDB: {self.db_path}")
        except Exception as e:
            self.logger.error(f"é€£æ¥è³‡æ–™åº«å¤±æ•—: {e}")
            raise

    def _get_duckdb_dtype(self, pandas_dtype: str) -> str:
        """æ›´å®Œæ•´çš„å‹æ…‹æ˜ å°„"""
        dtype_mapping = {
            'object': 'VARCHAR',
            'int64': 'BIGINT',
            'int32': 'INTEGER',
            'float64': 'DOUBLE',
            'float32': 'REAL',
            'datetime64[ns]': 'TIMESTAMP',
            'timedelta64[ns]': 'INTERVAL',
            'bool': 'BOOLEAN',
            'category': 'VARCHAR',
            'string': 'VARCHAR'
        }

        # è™•ç†è¤‡é›œçš„ datetime æ ¼å¼
        if 'datetime64' in pandas_dtype:
            return 'TIMESTAMP'

        return dtype_mapping.get(pandas_dtype, 'VARCHAR')

    def create_table_from_df(self, table_name: str, df: pd.DataFrame,
                             if_exists: str = 'fail') -> bool:
        """
        å¾ DataFrame å»ºç«‹è¡¨æ ¼

        Args:
            table_name: è¡¨æ ¼åç¨±
            df: pandas DataFrame
            if_exists: 'fail', 'replace', 'append'

        Returns:
            bool: æ˜¯å¦æˆåŠŸå»ºç«‹
        """
        try:
            # è¨˜éŒ„é–‹å§‹æ“ä½œ
            self.logger.info(f"é–‹å§‹å»ºç«‹è¡¨æ ¼ '{table_name}'ï¼Œæ¨¡å¼: {if_exists}")

            # æª¢æŸ¥è¡¨æ ¼æ˜¯å¦å·²å­˜åœ¨
            existing_tables = self.conn.sql("SHOW TABLES").df()
            table_exists = table_name in existing_tables['name'].values if not existing_tables.empty else False

            if table_exists:
                self.logger.debug(f"è¡¨æ ¼ '{table_name}' å·²å­˜åœ¨")
                if if_exists == 'fail':
                    raise ValueError(f"è¡¨æ ¼ {table_name} å·²å­˜åœ¨")
                elif if_exists == 'replace':
                    self.logger.warning(f"æ›¿æ›ç¾æœ‰è¡¨æ ¼ '{table_name}'")
                    self.conn.sql(f'DROP TABLE IF EXISTS "{table_name}"')
                elif if_exists == 'append':
                    # ç›´æ¥æ’å…¥è³‡æ–™åˆ°ç¾æœ‰è¡¨æ ¼
                    self.logger.info(f"å°‡è³‡æ–™é™„åŠ åˆ°ç¾æœ‰è¡¨æ ¼ '{table_name}'")
                    return self.insert_df_into_table(table_name, df)

            # å»ºç«‹æ¬„ä½å®šç¾©
            columns_with_types = []
            for col in df.columns:
                dtype_str = str(df[col].dtype)
                duckdb_dtype = self._get_duckdb_dtype(dtype_str)
                columns_with_types.append(f'"{col}" {duckdb_dtype}')
                self.logger.debug(f"æ¬„ä½ '{col}': {dtype_str} -> {duckdb_dtype}")

            columns_sql = ", ".join(columns_with_types)

            # å»ºç«‹è¡¨æ ¼
            self.conn.sql(f'CREATE TABLE "{table_name}" ({columns_sql})')
            self.logger.debug(f"è¡¨æ ¼çµæ§‹å»ºç«‹å®Œæˆ: {columns_sql}")

            # æ’å…¥è³‡æ–™
            self.conn.sql(f'INSERT INTO "{table_name}" SELECT * FROM df')

            self.logger.info(f"âœ… æˆåŠŸå»ºç«‹è¡¨æ ¼ '{table_name}'ï¼Œæ’å…¥ {len(df):,} ç­†è³‡æ–™")
            return True

        except Exception as e:
            self.logger.error(f"âŒ å»ºç«‹è¡¨æ ¼ '{table_name}' å¤±æ•—: {e}")
            return False

    def insert_df_into_table(self, table_name: str, df: pd.DataFrame) -> bool:
        """æ’å…¥è³‡æ–™åˆ°ç¾æœ‰è¡¨æ ¼"""
        try:
            # æª¢æŸ¥è¡¨æ ¼æ˜¯å¦å­˜åœ¨
            existing_tables = self.conn.sql("SHOW TABLES").df()
            if existing_tables.empty or table_name not in existing_tables['name'].values:
                raise ValueError(f"è¡¨æ ¼ {table_name} ä¸å­˜åœ¨")

            self.conn.sql(f'INSERT INTO "{table_name}" SELECT * FROM df')
            self.logger.info(f"âœ… æˆåŠŸæ’å…¥ {len(df):,} ç­†è³‡æ–™åˆ° '{table_name}'")
            return True

        except Exception as e:
            self.logger.error(f"âŒ æ’å…¥è³‡æ–™åˆ° '{table_name}' å¤±æ•—: {e}")
            return False

    def upsert_df_into_table(self, table_name: str, df: pd.DataFrame,
                             key_columns: list) -> bool:
        """
        æ›´æ–°æˆ–æ’å…¥è³‡æ–™ (upsert)

        Args:
            table_name: è¡¨æ ¼åç¨±
            df: è¦æ’å…¥çš„è³‡æ–™
            key_columns: ç”¨æ–¼åˆ¤æ–·é‡è¤‡çš„æ¬„ä½
        """
        try:
            self.logger.info(f"é–‹å§‹ upsert æ“ä½œåˆ° '{table_name}'ï¼Œä½¿ç”¨éµ: {key_columns}")

            # å…ˆåˆªé™¤é‡è¤‡çš„è¨˜éŒ„
            key_conditions = []
            for key_col in key_columns:
                unique_values = df[key_col].unique()
                if len(unique_values) > 0:
                    values_str = "', '".join(str(v) for v in unique_values)
                    key_conditions.append(f'"{key_col}" IN (\'{values_str}\')')

            if key_conditions:
                where_clause = " AND ".join(key_conditions)
                deleted_result = \
                    self.conn.sql(f'SELECT COUNT(*) as count FROM "{table_name}" WHERE {where_clause}').df()
                deleted_count = deleted_result.iloc[0]['count'] if not deleted_result.empty else 0

                self.conn.sql(f'DELETE FROM "{table_name}" WHERE {where_clause}')
                self.logger.info(f"åˆªé™¤äº† {deleted_count} ç­†é‡è¤‡è¨˜éŒ„")

            # æ’å…¥æ–°è³‡æ–™
            result = self.insert_df_into_table(table_name, df)
            if result:
                self.logger.info("âœ… Upsert æ“ä½œå®Œæˆ")
            return result

        except Exception as e:
            self.logger.error(f"âŒ Upsert æ“ä½œå¤±æ•—: {e}")
            return False

    def query_to_df(self, query: str) -> Optional[pd.DataFrame]:
        """åŸ·è¡ŒæŸ¥è©¢ä¸¦è¿”å› DataFrame"""
        try:
            self.logger.debug(f"åŸ·è¡ŒæŸ¥è©¢: {query[:100]}...")
            result = self.conn.sql(query).df()
            self.logger.debug(f"æŸ¥è©¢è¿”å› {len(result)} ç­†è¨˜éŒ„")
            return result
        except Exception as e:
            self.logger.error(f"âŒ æŸ¥è©¢å¤±æ•—: {e}")
            return None

    def delete_data(self, query: str):
        """åŸ·è¡ŒDELETE"""
        try:
            self.logger.debug(f"åŸ·è¡ŒæŸ¥è©¢: {query[:100]}...")
            self.conn.sql(query)
            self.logger.debug("Successfuly deleted")
        except Exception as e:
            self.logger.error(f"âŒ Failed to delete: {e}")

    def show_tables(self) -> Optional[pd.DataFrame]:
        """é¡¯ç¤ºæ‰€æœ‰è¡¨æ ¼"""
        self.logger.debug("ç²å–æ‰€æœ‰è¡¨æ ¼åˆ—è¡¨")
        return self.query_to_df("SHOW TABLES")

    def describe_table(self, table_name: str) -> Optional[pd.DataFrame]:
        """æè¿°è¡¨æ ¼çµæ§‹"""
        self.logger.debug(f"ç²å–è¡¨æ ¼ '{table_name}' çš„çµæ§‹")
        return self.query_to_df(f'DESCRIBE "{table_name}"')

    def get_table_info(self, table_name: str) -> Dict[str, Any]:
        """ç²å–è¡¨æ ¼è©³ç´°è³‡è¨Š"""
        try:
            self.logger.debug(f"ç²å–è¡¨æ ¼ '{table_name}' çš„è©³ç´°è³‡è¨Š")

            row_count = self.conn.sql(f'SELECT COUNT(*) as count FROM "{table_name}"').df().iloc[0]['count']
            schema = self.describe_table(table_name)

            info = {
                'table_name': table_name,
                'row_count': row_count,
                'columns': schema['column_name'].tolist() if schema is not None else [],
                'schema': schema
            }

            self.logger.info(f"è¡¨æ ¼ '{table_name}' åŒ…å« {row_count:,} ç­†è¨˜éŒ„ï¼Œ{len(info['columns'])} å€‹æ¬„ä½")
            return info

        except Exception as e:
            self.logger.error(f"âŒ ç²å–è¡¨æ ¼ '{table_name}' è³‡è¨Šå¤±æ•—: {e}")
            return {}

    def alter_column_type(self, table_name: str, column_name: str, new_type: str,
                          validate_conversion: bool = True) -> bool:
        """
        ä¿®æ”¹è¡¨æ ¼æ¬„ä½çš„è³‡æ–™å‹æ…‹

        Args:
            table_name: è¡¨æ ¼åç¨±
            column_name: æ¬„ä½åç¨±
            new_type: æ–°çš„è³‡æ–™å‹æ…‹ (å¦‚ 'BIGINT', 'VARCHAR', 'DOUBLE' ç­‰)
            validate_conversion: æ˜¯å¦å…ˆé©—è­‰è³‡æ–™èƒ½å¦è½‰æ›

        Returns:
            bool: æ˜¯å¦æˆåŠŸä¿®æ”¹
        """
        try:
            self.logger.info(f"é–‹å§‹ä¿®æ”¹è¡¨æ ¼ '{table_name}' çš„æ¬„ä½ '{column_name}' å‹æ…‹ç‚º {new_type}")

            # å…ˆé©—è­‰è³‡æ–™æ˜¯å¦èƒ½è½‰æ› (å¦‚æœè¦æ±‚çš„è©±)
            if validate_conversion:
                self.logger.debug(f"é©—è­‰ '{column_name}' æ¬„ä½è³‡æ–™æ˜¯å¦èƒ½è½‰æ›ç‚º {new_type}")

                # æª¢æŸ¥æ˜¯å¦æœ‰ç„¡æ³•è½‰æ›çš„è³‡æ–™
                if new_type.upper() in ['BIGINT', 'INTEGER', 'DOUBLE', 'REAL']:
                    validation_query = f"""
                    SELECT COUNT(*) as invalid_count
                    FROM "{table_name}"
                    WHERE "{column_name}" IS NOT NULL
                    AND TRY_CAST("{column_name}" AS {new_type}) IS NULL
                    """

                    invalid_result = self.conn.sql(validation_query).df()
                    invalid_count = invalid_result.iloc[0]['invalid_count'] if not invalid_result.empty else 0

                    if invalid_count > 0:
                        # é¡¯ç¤ºä¸€äº›ç„¡æ³•è½‰æ›çš„ç¯„ä¾‹
                        sample_query = f"""
                        SELECT "{column_name}" as invalid_value
                        FROM "{table_name}"
                        WHERE "{column_name}" IS NOT NULL
                        AND TRY_CAST("{column_name}" AS {new_type}) IS NULL
                        LIMIT 5
                        """
                        samples = self.conn.sql(sample_query).df()
                        self.logger.error(f"âŒ ç™¼ç¾ {invalid_count} ç­†ç„¡æ³•è½‰æ›çš„è³‡æ–™ï¼Œç¯„ä¾‹: {samples['invalid_value'].tolist()}")
                        return False

                    self.logger.info(f"âœ… æ‰€æœ‰è³‡æ–™éƒ½èƒ½æˆåŠŸè½‰æ›ç‚º {new_type}")

            # åŸ·è¡Œæ¬„ä½å‹æ…‹ä¿®æ”¹
            alter_query = f'ALTER TABLE "{table_name}" ALTER COLUMN "{column_name}" TYPE {new_type}'
            self.conn.sql(alter_query)

            self.logger.info(f"âœ… æˆåŠŸä¿®æ”¹æ¬„ä½ '{column_name}' å‹æ…‹ç‚º {new_type}")

            # é©—è­‰ä¿®æ”¹çµæœ
            schema = self.describe_table(table_name)
            if schema is not None:
                column_info = schema[schema['column_name'] == column_name]
                if not column_info.empty:
                    actual_type = column_info.iloc[0]['column_type']
                    self.logger.info(f"ç¢ºèª: æ¬„ä½ '{column_name}' ç›®å‰å‹æ…‹ç‚º {actual_type}")

            return True

        except Exception as e:
            self.logger.error(f"âŒ ä¿®æ”¹æ¬„ä½å‹æ…‹å¤±æ•—: {e}")
            return False

    def clean_numeric_column(self, table_name: str, column_name: str,
                             remove_chars: list = None,
                             preview_only: bool = False) -> bool:
        """
        æ¸…ç†æ•¸å­—æ¬„ä½ä¸­çš„éæ•¸å­—å­—ç¬¦

        Args:
            table_name: è¡¨æ ¼åç¨±
            column_name: æ¬„ä½åç¨±
            remove_chars: è¦ç§»é™¤çš„å­—ç¬¦åˆ—è¡¨ï¼Œé è¨­ç‚º [',', '$', 'â‚¬', 'Â¥', ' ']
            preview_only: åƒ…é è¦½æ¸…ç†çµæœï¼Œä¸å¯¦éš›åŸ·è¡Œæ›´æ–°

        Returns:
            bool: æ˜¯å¦æˆåŠŸæ¸…ç†
        """
        try:
            if remove_chars is None:
                remove_chars = [',', '$', 'â‚¬', 'Â¥', ' ', 'ï¿¥', 'â‚©', 'Â£']  # å¸¸è¦‹çš„åƒåˆ†ä½ç¬¦è™Ÿå’Œè²¨å¹£ç¬¦è™Ÿ

            self.logger.info(f"é–‹å§‹æ¸…ç†è¡¨æ ¼ '{table_name}' çš„æ¬„ä½ '{column_name}'")
            self.logger.debug(f"å°‡ç§»é™¤å­—ç¬¦: {remove_chars}")

            # é¦–å…ˆæª¢æŸ¥éœ€è¦æ¸…ç†çš„è³‡æ–™æ•¸é‡
            check_conditions = []
            for char in remove_chars:
                check_conditions.append(f'"{column_name}" LIKE \'%{char}%\'')

            check_query = f"""
            SELECT COUNT(*) as dirty_count
            FROM "{table_name}"
            WHERE "{column_name}" IS NOT NULL
            AND ({' OR '.join(check_conditions)})
            """

            dirty_result = self.conn.sql(check_query).df()
            dirty_count = dirty_result.iloc[0]['dirty_count'] if not dirty_result.empty else 0

            if dirty_count == 0:
                self.logger.info(f"âœ… æ¬„ä½ '{column_name}' ç„¡éœ€æ¸…ç†")
                return True

            self.logger.info(f"ç™¼ç¾ {dirty_count} ç­†éœ€è¦æ¸…ç†çš„è³‡æ–™")

            # é¡¯ç¤ºæ¸…ç†å‰å¾Œçš„ç¯„ä¾‹
            sample_query = f"""
            SELECT
                "{column_name}" as original_value,
            """

            # å»ºç«‹æ¸…ç†é‚è¼¯ - é€æ­¥ç§»é™¤æ¯å€‹å­—ç¬¦
            cleaned_expression = f'"{column_name}"'
            for char in remove_chars:
                cleaned_expression = f"REPLACE({cleaned_expression}, '{char}', '')"

            sample_query += f"""
                {cleaned_expression} as cleaned_value
            FROM "{table_name}"
            WHERE "{column_name}" IS NOT NULL
            AND ({' OR '.join(check_conditions)})
            LIMIT 10
            """

            sample_result = self.conn.sql(sample_query).df()

            self.logger.info("æ¸…ç†ç¯„ä¾‹:")
            for _, row in sample_result.iterrows():
                self.logger.info(f"  '{row['original_value']}' â†’ '{row['cleaned_value']}'")

            if preview_only:
                self.logger.info("ğŸ“‹ é è¦½æ¨¡å¼ï¼šæœªåŸ·è¡Œå¯¦éš›æ›´æ–°")
                return True

            # åŸ·è¡Œæ¸…ç†
            update_query = f"""
            UPDATE "{table_name}"
            SET "{column_name}" = {cleaned_expression}
            WHERE "{column_name}" IS NOT NULL
            AND ({' OR '.join(check_conditions)})
            """

            self.conn.sql(update_query)

            # é©—è­‰æ¸…ç†çµæœ
            verify_query = f"""
            SELECT COUNT(*) as remaining_dirty
            FROM "{table_name}"
            WHERE "{column_name}" IS NOT NULL
            AND ({' OR '.join(check_conditions)})
            """

            verify_result = self.conn.sql(verify_query).df()
            remaining_dirty = verify_result.iloc[0]['remaining_dirty'] if not verify_result.empty else 0

            if remaining_dirty == 0:
                self.logger.info(f"âœ… æˆåŠŸæ¸…ç† {dirty_count} ç­†è³‡æ–™")
            else:
                self.logger.warning(f"âš ï¸ æ¸…ç†å®Œæˆï¼Œä½†ä»æœ‰ {remaining_dirty} ç­†è³‡æ–™å¯èƒ½éœ€è¦é¡å¤–è™•ç†")

            return True

        except Exception as e:
            self.logger.error(f"âŒ æ¸…ç†æ•¸æ“šå¤±æ•—: {e}")
            return False

    def clean_and_convert_column(self, table_name: str, column_name: str,
                                 target_type: str,
                                 remove_chars: list = None,
                                 handle_empty_as_null: bool = True) -> bool:
        """
        æ¸…ç†ä¸¦è½‰æ›æ¬„ä½å‹æ…‹çš„ä¸€ç«™å¼æ–¹æ³•

        Args:
            table_name: è¡¨æ ¼åç¨±
            column_name: æ¬„ä½åç¨±
            target_type: ç›®æ¨™è³‡æ–™å‹æ…‹
            remove_chars: è¦ç§»é™¤çš„å­—ç¬¦åˆ—è¡¨
            handle_empty_as_null: æ˜¯å¦å°‡ç©ºå­—ä¸²è½‰æ›ç‚º NULL

        Returns:
            bool: æ˜¯å¦æˆåŠŸå®Œæˆæ¸…ç†å’Œè½‰æ›
        """
        try:
            self.logger.info(f"ğŸ§¹ é–‹å§‹æ¸…ç†ä¸¦è½‰æ›æ¬„ä½ '{column_name}' ç‚º {target_type}")

            # Step 1: æ¸…ç†æ•¸æ“š
            clean_success = self.clean_numeric_column(
                table_name=table_name,
                column_name=column_name,
                remove_chars=remove_chars,
                preview_only=False
            )

            if not clean_success:
                return False

            # Step 2: è™•ç†ç©ºå­—ä¸²
            if handle_empty_as_null:
                empty_query = f"""
                UPDATE "{table_name}"
                SET "{column_name}" = NULL
                WHERE "{column_name}" = '' OR "{column_name}" = ' '
                """
                self.conn.sql(empty_query)
                self.logger.debug("å·²å°‡ç©ºå­—ä¸²è½‰æ›ç‚º NULL")

            # Step 3: æœ€çµ‚é©—è­‰
            validation_success = self._validate_conversion(table_name, column_name, target_type)
            if not validation_success:
                return False

            # Step 4: åŸ·è¡Œå‹æ…‹è½‰æ›
            conversion_success = self.alter_column_type(
                table_name=table_name,
                column_name=column_name,
                new_type=target_type,
                validate_conversion=False  # å·²ç¶“é©—è­‰éäº†
            )

            if conversion_success:
                self.logger.info(f"ğŸ‰ æˆåŠŸå®Œæˆæ¸…ç†å’Œè½‰æ›ï¼æ¬„ä½ '{column_name}' ç¾åœ¨æ˜¯ {target_type} å‹æ…‹")

            return conversion_success

        except Exception as e:
            self.logger.error(f"âŒ æ¸…ç†å’Œè½‰æ›éç¨‹å¤±æ•—: {e}")
            return False

    def _validate_conversion(self, table_name: str, column_name: str, target_type: str) -> bool:
        """å…§éƒ¨æ–¹æ³•ï¼šé©—è­‰æ¸…ç†å¾Œçš„è³‡æ–™æ˜¯å¦èƒ½æˆåŠŸè½‰æ›"""
        try:
            if target_type.upper() in ['BIGINT', 'INTEGER', 'DOUBLE', 'REAL']:
                validation_query = f"""
                SELECT COUNT(*) as invalid_count
                FROM "{table_name}"
                WHERE "{column_name}" IS NOT NULL
                AND TRY_CAST("{column_name}" AS {target_type}) IS NULL
                """

                invalid_result = self.conn.sql(validation_query).df()
                invalid_count = invalid_result.iloc[0]['invalid_count'] if not invalid_result.empty else 0

                if invalid_count > 0:
                    # é¡¯ç¤ºä»ç„¶ç„¡æ³•è½‰æ›çš„è³‡æ–™
                    sample_query = f"""
                    SELECT "{column_name}" as problematic_value
                    FROM "{table_name}"
                    WHERE "{column_name}" IS NOT NULL
                    AND TRY_CAST("{column_name}" AS {target_type}) IS NULL
                    LIMIT 5
                    """
                    samples = self.conn.sql(sample_query).df()
                    self.logger.error(f"âŒ æ¸…ç†å¾Œä»æœ‰ {invalid_count} ç­†ç„¡æ³•è½‰æ›çš„è³‡æ–™")
                    self.logger.error(f"ç¯„ä¾‹: {samples['problematic_value'].tolist()}")
                    return False

                self.logger.info(f"âœ… æ¸…ç†å¾Œæ‰€æœ‰è³‡æ–™éƒ½èƒ½æˆåŠŸè½‰æ›ç‚º {target_type}")

            return True

        except Exception as e:
            self.logger.error(f"âŒ é©—è­‰è½‰æ›å¤±æ•—: {e}")
            return False

    def preview_column_values(self, table_name: str, column_name: str,
                              limit: int = 20, show_unique: bool = True) -> Optional[pd.DataFrame]:
        """
        é è¦½æ¬„ä½çš„å€¼ï¼Œç”¨æ–¼äº†è§£è³‡æ–™æ ¼å¼

        Args:
            table_name: è¡¨æ ¼åç¨±
            column_name: æ¬„ä½åç¨±
            limit: é¡¯ç¤ºç­†æ•¸é™åˆ¶
            show_unique: æ˜¯å¦åªé¡¯ç¤ºå”¯ä¸€å€¼

        Returns:
            DataFrame: åŒ…å«ç¯„ä¾‹è³‡æ–™
        """
        try:
            if show_unique:
                query = f"""
                SELECT DISTINCT "{column_name}" as value, COUNT(*) as count
                FROM "{table_name}"
                WHERE "{column_name}" IS NOT NULL
                GROUP BY "{column_name}"
                ORDER BY count DESC
                LIMIT {limit}
                """
            else:
                query = f"""
                SELECT "{column_name}" as value
                FROM "{table_name}"
                WHERE "{column_name}" IS NOT NULL
                LIMIT {limit}
                """

            result = self.conn.sql(query).df()
            self.logger.info(f"æ¬„ä½ '{column_name}' çš„ç¯„ä¾‹è³‡æ–™:")
            print(result)
            return result

        except Exception as e:
            self.logger.error(f"âŒ é è¦½è³‡æ–™å¤±æ•—: {e}")
            return None

    def close(self):
        """é—œé–‰è³‡æ–™åº«é€£æ¥"""
        if self.conn:
            self.conn.close()
            self.logger.info("ğŸ” è³‡æ–™åº«é€£æ¥å·²é—œé–‰")

    def __enter__(self):
        """Context manager å…¥å£"""
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        """Context manager å‡ºå£"""
        self.close()

    def drop_table(self, table_name: str,
                   if_exists: bool = True,
                   confirm: bool = True) -> bool:
        """
        åˆªé™¤è¡¨æ ¼

        Args:
            table_name: è¡¨æ ¼åç¨±
            if_exists: å¦‚æœç‚º True ä½¿ç”¨ DROP TABLE IF EXISTSï¼Œé¿å…è¡¨æ ¼ä¸å­˜åœ¨æ™‚å ±éŒ¯
            confirm: æ˜¯å¦éœ€è¦ç¢ºèªæ“ä½œï¼ˆå®‰å…¨æ©Ÿåˆ¶ï¼‰

        Returns:
            bool: æ˜¯å¦æˆåŠŸåˆªé™¤
        """
        try:
            # æª¢æŸ¥è¡¨æ ¼æ˜¯å¦å­˜åœ¨
            existing_tables = self.conn.sql("SHOW TABLES").df()
            table_exists = table_name in existing_tables['name'].values if not existing_tables.empty else False

            if not table_exists and not if_exists:
                self.logger.error(f"âŒ è¡¨æ ¼ '{table_name}' ä¸å­˜åœ¨")
                return False
            elif not table_exists and if_exists:
                self.logger.warning(f"âš ï¸ è¡¨æ ¼ '{table_name}' ä¸å­˜åœ¨ï¼Œç„¡éœ€åˆªé™¤")
                return True

            # ç²å–è¡¨æ ¼è³‡è¨Šç”¨æ–¼æ—¥èªŒ
            table_info = self.get_table_info(table_name)
            row_count = table_info.get('row_count', 0)

            # ç¢ºèªæ©Ÿåˆ¶
            if confirm:
                self.logger.warning(f"âš ï¸ å³å°‡åˆªé™¤è¡¨æ ¼ '{table_name}' (åŒ…å« {row_count:,} ç­†è³‡æ–™)")
                # åœ¨ç”Ÿç”¢ç’°å¢ƒä¸­ï¼Œæ‚¨å¯èƒ½æƒ³è¦å¯¦ä½œæ›´å¼·çš„ç¢ºèªæ©Ÿåˆ¶

            # åŸ·è¡Œåˆªé™¤
            drop_sql = f'DROP TABLE {"IF EXISTS " if if_exists else ""}"{table_name}"'
            self.conn.sql(drop_sql)

            self.logger.info(f"âœ… æˆåŠŸåˆªé™¤è¡¨æ ¼ '{table_name}' (åŸæœ‰ {row_count:,} ç­†è³‡æ–™)")
            return True

        except Exception as e:
            self.logger.error(f"âŒ åˆªé™¤è¡¨æ ¼ '{table_name}' å¤±æ•—: {e}")
            return False

    def truncate_table(self, table_name: str) -> bool:
        """
        æ¸…ç©ºè¡¨æ ¼è³‡æ–™ä½†ä¿ç•™çµæ§‹

        Args:
            table_name: è¡¨æ ¼åç¨±

        Returns:
            bool: æ˜¯å¦æˆåŠŸæ¸…ç©º
        """
        try:
            # æª¢æŸ¥è¡¨æ ¼æ˜¯å¦å­˜åœ¨
            existing_tables = self.conn.sql("SHOW TABLES").df()
            if existing_tables.empty or table_name not in existing_tables['name'].values:
                self.logger.error(f"âŒ è¡¨æ ¼ '{table_name}' ä¸å­˜åœ¨")
                return False

            # ç²å–æ¸…ç©ºå‰çš„è¨˜éŒ„æ•¸
            row_count = self.conn.sql(f'SELECT COUNT(*) as count FROM "{table_name}"').df().iloc[0]['count']

            # æ¸…ç©ºè¡¨æ ¼
            self.conn.sql(f'DELETE FROM "{table_name}"')

            self.logger.info(f"âœ… æˆåŠŸæ¸…ç©ºè¡¨æ ¼ '{table_name}' (åˆªé™¤äº† {row_count:,} ç­†è³‡æ–™)")
            return True

        except Exception as e:
            self.logger.error(f"âŒ æ¸…ç©ºè¡¨æ ¼ '{table_name}' å¤±æ•—: {e}")
            return False

    def backup_table(self, table_name: str, backup_format: str = 'parquet',
                     backup_path: str = None) -> bool:
        """
        å‚™ä»½è¡¨æ ¼è³‡æ–™

        Args:
            table_name: è¡¨æ ¼åç¨±
            backup_format: å‚™ä»½æ ¼å¼ ('parquet', 'csv', 'json')
            backup_path: å‚™ä»½æª”æ¡ˆè·¯å¾‘ï¼Œå¦‚æœç‚º None å‰‡è‡ªå‹•ç”Ÿæˆ

        Returns:
            bool: æ˜¯å¦æˆåŠŸå‚™ä»½
        """
        try:

            if backup_path is None:
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                backup_path = f"{table_name}_backup_{timestamp}.{backup_format}"

            # æª¢æŸ¥è¡¨æ ¼æ˜¯å¦å­˜åœ¨
            existing_tables = self.conn.sql("SHOW TABLES").df()
            if existing_tables.empty or table_name not in existing_tables['name'].values:
                self.logger.error(f"âŒ è¡¨æ ¼ '{table_name}' ä¸å­˜åœ¨")
                return False

            # åŸ·è¡Œå‚™ä»½
            if backup_format.lower() == 'parquet':
                self.conn.sql(f'COPY (SELECT * FROM "{table_name}") TO \'{backup_path}\' (FORMAT PARQUET)')
            elif backup_format.lower() == 'csv':
                self.conn.sql(f'COPY (SELECT * FROM "{table_name}") TO \'{backup_path}\' (FORMAT CSV, HEADER)')
            elif backup_format.lower() == 'json':
                self.conn.sql(f'COPY (SELECT * FROM "{table_name}") TO \'{backup_path}\' (FORMAT JSON)')
            else:
                raise ValueError(f"ä¸æ”¯æ´çš„å‚™ä»½æ ¼å¼: {backup_format}")

            # ç²å–å‚™ä»½è³‡è¨Š
            table_info = self.get_table_info(table_name)
            row_count = table_info.get('row_count', 0)

            self.logger.info(f"âœ… æˆåŠŸå‚™ä»½è¡¨æ ¼ '{table_name}' åˆ° '{backup_path}' ({row_count:,} ç­†è³‡æ–™)")
            return True

        except Exception as e:
            self.logger.error(f"âŒ å‚™ä»½è¡¨æ ¼ '{table_name}' å¤±æ•—: {e}")
            return False

    def execute_transaction(self, operations: list) -> bool:
        """
        åŸ·è¡Œäº‹å‹™æ“ä½œ

        Args:
            operations: SQL æ“ä½œåˆ—è¡¨

        Returns:
            bool: æ˜¯å¦æˆåŠŸåŸ·è¡Œæ‰€æœ‰æ“ä½œ
        """
        try:
            self.logger.info(f"é–‹å§‹åŸ·è¡Œäº‹å‹™æ“ä½œ (å…± {len(operations)} å€‹æ“ä½œ)")

            # é–‹å§‹äº‹å‹™
            self.conn.sql("BEGIN TRANSACTION")

            for i, operation in enumerate(operations, 1):
                try:
                    self.logger.debug(f"åŸ·è¡Œæ“ä½œ {i}/{len(operations)}: {operation[:100]}...")
                    self.conn.sql(operation)
                except Exception as e:
                    self.logger.error(f"âŒ æ“ä½œ {i} å¤±æ•—: {e}")
                    self.conn.sql("ROLLBACK")
                    self.logger.error("ğŸ”„ äº‹å‹™å·²å›æ»¾")
                    return False

            # æäº¤äº‹å‹™
            self.conn.sql("COMMIT")
            self.logger.info(f"âœ… æˆåŠŸåŸ·è¡Œæ‰€æœ‰ {len(operations)} å€‹æ“ä½œ")
            return True

        except Exception as e:
            self.logger.error(f"âŒ äº‹å‹™åŸ·è¡Œå¤±æ•—: {e}")
            try:
                self.conn.sql("ROLLBACK")
                self.logger.error("ğŸ”„ äº‹å‹™å·²å›æ»¾")
            except Exception as err:
                pass
            return False

    def validate_data_integrity(self, table_name: str,
                                checks: dict = None) -> dict:
        """
        é©—è­‰è³‡æ–™å®Œæ•´æ€§

        Args:
            table_name: è¡¨æ ¼åç¨±
            checks: è‡ªå®šç¾©æª¢æŸ¥è¦å‰‡

        Returns:
            dict: é©—è­‰çµæœ
        """
        try:
            self.logger.info(f"é–‹å§‹é©—è­‰è¡¨æ ¼ '{table_name}' çš„è³‡æ–™å®Œæ•´æ€§")

            results = {
                'table_name': table_name,
                'total_rows': 0,
                'null_counts': {},
                'duplicate_rows': 0,
                'data_types': {},
                'custom_checks': {}
            }

            # åŸºæœ¬çµ±è¨ˆ
            total_rows = self.conn.sql(f'SELECT COUNT(*) as count FROM "{table_name}"').df().iloc[0]['count']
            results['total_rows'] = total_rows

            # æª¢æŸ¥æ¯å€‹æ¬„ä½çš„NULLå€¼
            schema = self.describe_table(table_name)
            if schema is not None:
                for _, col_info in schema.iterrows():
                    col_name = col_info['column_name']
                    null_count = (self.conn.sql(
                        f'SELECT COUNT(*) as count FROM "{table_name}" WHERE "{col_name}" IS NULL')
                        .df()
                        .iloc[0]['count']
                    )
                    results['null_counts'][col_name] = null_count
                    results['data_types'][col_name] = col_info['column_type']

            # æª¢æŸ¥é‡è¤‡è¡Œ
            duplicate_count = self.conn.sql(f'''
                SELECT COUNT(*) as count FROM (
                    SELECT COUNT(*) as row_count
                    FROM "{table_name}"
                    GROUP BY *
                    HAVING COUNT(*) > 1
                )
            ''').df().iloc[0]['count']
            results['duplicate_rows'] = duplicate_count

            # è‡ªå®šç¾©æª¢æŸ¥
            if checks:
                for check_name, check_sql in checks.items():
                    try:
                        check_result = self.conn.sql(check_sql.format(table_name=table_name)).df()
                        results['custom_checks'][check_name] = check_result.to_dict('records')
                    except Exception as e:
                        results['custom_checks'][check_name] = f"Error: {e}"

            self.logger.info("âœ… å®Œæˆè³‡æ–™å®Œæ•´æ€§é©—è­‰")
            return results

        except Exception as e:
            self.logger.error(f"âŒ è³‡æ–™å®Œæ•´æ€§é©—è­‰å¤±æ•—: {e}")
            return {}


def create_table(table_name: str, 
                 df: pd.DataFrame, 
                 db_path="bank_statements.duckdb", 
                 log_file="duckdb_operations.log", 
                 log_level="DEBUG"):
    """ä½¿ç”¨ç¯„ä¾‹ï¼šåŸºæœ¬æ“ä½œ"""

    db_path = db_path
    log_file = log_file

    # å»ºç«‹DuckDBç®¡ç†å™¨ï¼ŒåŒæ™‚è¼¸å‡ºåˆ°terminalå’Œæª”æ¡ˆ
    with DuckDBManager(
        db_path=db_path
    ) as db_manager:

        # å»ºç«‹è¡¨æ ¼ï¼ˆæ­£ç¢ºçš„æ–¹å¼ï¼Œåªæœƒæ’å…¥ä¸€æ¬¡ï¼‰
        success1 = db_manager.create_table_from_df(
            table_name,
            df,
        )

        if success1:
            # é¡¯ç¤ºè©³ç´°è³‡è¨Š
            info = db_manager.get_table_info(table_name)
            print(f"\nğŸ“‹ è¡¨æ ¼ {table_name}:")
            print(f"   è¨˜éŒ„æ•¸: {info.get('row_count', 0):,}")
            print(f"   æ¬„ä½æ•¸: {len(info.get('columns', []))}")
            return info
        else:
            return None

def insert_table(table_name: str, 
                 df: pd.DataFrame, 
                 db_path="bank_statements.duckdb", 
                 log_file="duckdb_operations.log", 
                 log_level="DEBUG"):
    """ä½¿ç”¨ç¯„ä¾‹ï¼šåŸºæœ¬æ“ä½œ"""

    db_path = db_path
    log_file = log_file

    # å»ºç«‹DuckDBç®¡ç†å™¨ï¼ŒåŒæ™‚è¼¸å‡ºåˆ°terminalå’Œæª”æ¡ˆ
    with DuckDBManager(
        db_path=db_path
    ) as db_manager:

        # å»ºç«‹è¡¨æ ¼ï¼ˆæ­£ç¢ºçš„æ–¹å¼ï¼Œåªæœƒæ’å…¥ä¸€æ¬¡ï¼‰
        success1 = db_manager.insert_df_into_table(
            table_name,
            df,
        )

        if success1:
            # é¡¯ç¤ºè©³ç´°è³‡è¨Š
            info = db_manager.get_table_info(table_name)
            print(f"\nğŸ“‹ è¡¨æ ¼ {table_name}:")
            print(f"   è¨˜éŒ„æ•¸: {info.get('row_count', 0):,}")
            print(f"   æ¬„ä½æ•¸: {len(info.get('columns', []))}")
            return info
        else:
            return None

def alter_column_dtype(table_name: str, 
                       column_name: str, 
                       new_type: str = "BIGINT", 
                       db_path: str = "bank_statements.duckdb", 
                       log_file: str = "duckdb_operations.log", 
                       log_level: str = "DEBUG"):

    with DuckDBManager(
        db_path=db_path
    ) as db_manager:

        # Method 1: Preview the data first to understand the format
        print("=== Step 1: Preview current data ===")
        db_manager.preview_column_values(
            table_name=table_name,
            column_name=column_name,
            limit=10,
            show_unique=True
        )

        # Method 2: Preview cleaning (without actually changing data)
        print("\n=== Step 2: Preview cleaning ===")
        db_manager.clean_numeric_column(
            table_name=table_name,
            column_name=column_name,
            remove_chars=[','],  # Only remove commas
            preview_only=True
        )

        # Method 3: Actually clean and convert in one go
        print("\n=== Step 3: Clean and convert ===")
        success = db_manager.clean_and_convert_column(
            table_name=table_name,
            column_name=column_name,
            target_type=new_type,
            remove_chars=[','],  # Remove commas
            handle_empty_as_null=True
        )

        if success:
            print("ğŸ‰ Success! Let's verify the result:")

            # Verify the schema change
            schema = db_manager.describe_table(table_name)
            print(schema[schema['column_name'] == column_name])

            # Check some sample data
            sample_data = db_manager.query_to_df(f"""
            SELECT {column_name}
            FROM {table_name}
            WHERE {column_name} IS NOT NULL
            LIMIT 5
            """)
            print("\nSample converted data:")
            print(sample_data)

def drop_table(table_name: str, db_path="bank_statements.duckdb", log_file="duckdb_operations.log", log_level="DEBUG"):
    with DuckDBManager(
        db_path=db_path
    ) as db_manager:

        query = \
            f"""
            DROP TABLE IF EXISTS {table_name}
            """

        db_manager.drop_table(table_name)

def backup_table(table_name: str, 
                 db_path="bank_statements.duckdb", 
                 log_file="duckdb_operations.log", 
                 log_level="DEBUG", 
                 backup_format: str = 'parquet', 
                 backup_path: str = None):
    with DuckDBManager(
        db_path=db_path
    ) as db_manager:

        db_manager.backup_table(
            table_name=table_name,
            backup_format=backup_format,
            backup_path=backup_path
        )

if __name__ == "__main__":
    DB_PATH = "bank_statements.duckdb"
    LOG_FILE = "duckdb_operations.log"
    print(1)
    
